{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Data Cleaning Functions</center> \n",
    "## <center>For Southern Africa electricity demand data sets</center> \n",
    "\n",
    "- There's a function for each country in Southern Africa \n",
    "- The functions are set to pull the demand informaiton for the year 2018 \n",
    "- Functions export csv files \n",
    "\n",
    "### You will need the following libraries to run the data cleaning functions \n",
    "- pandas \n",
    "- numpy\n",
    "- os \n",
    "- calendar\n",
    "- datetime\n",
    "    - date\n",
    "    - timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import calendar\n",
    "from datetime import date , timedelta   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lesotho Data Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a user-defined function UDF for lesotho electricity demand data set \n",
    "\n",
    "def lesotho_df_cleaning(a,b):\n",
    "    \"\"\" This function will clean raw data sets in the format of the Lesotho_Load_Profile_2017_2019 xlsx file\n",
    "        and create a dataframe with the demand,hour,year,month,day columns from the dataset. Then it will export a csv file to your directory. \n",
    "        - The arugment 'a' is the path to where you stored your xlsx file with the data set to clean \n",
    "        - The argument 'b' is the path to where you want to store the new 'clean' csv file dataframe: \n",
    "                    example - '/(your desired directory path)/(name of file).csv'\"\"\" \n",
    "    \n",
    "    \n",
    "    path = a \n",
    "    lesotho_raw_data_df = pd.read_excel(path, sheet_name = \"2018\")                 # pulling the second sheet from the xlsx file and automatically turns the results into a dataframe \n",
    "\n",
    "    #pulling desired columns using iloc and drop funciton\n",
    "    lesotho_df = lesotho_raw_data_df.iloc[:, 1:4].drop([0,1],axis= 0).copy()       # using iloc() to pull desired columns into a dataframe and using drop() to drop the first two rows \n",
    "    lesotho_df.rename(columns={'Unnamed: 1':\"date_time\",\"Unnamed: 2\":\"hour\", \"Unnamed: 3\":\"system_demand_[mw]\"}, inplace = True) # renaming columns with inplace = True\n",
    "    \n",
    "    LESO_df = lesotho_df.reset_index(drop = True)                                  # reseting index \n",
    "    LESO_df['date_time'] = LESO_df['date_time'].astype('str')                      # changing date_time data type into string \n",
    " \n",
    "    LESO_df[['date','time']] = LESO_df.date_time.str.split(\" \", expand=True)       # spliting the date_time column into 2 new columns titled date and hour\n",
    "    LESO_df[['year','month','day']] = LESO_df.date.str.split(\"-\", expand=True)     # spliting the date column into 3 new columns titled year month day\n",
    "    lesotho_demand_df = LESO_df.iloc[:, 1:8].copy()                                # creating new dataframe not including first column at 0\n",
    "    lesotho_demand_df.drop([\"date\",\"time\"], axis=1, inplace = True)                # droping columns titled data and time \n",
    "    \n",
    "    lesotho_demand_df['hour'] = lesotho_demand_df['hour'].astype('str')            # converting to string to convert to datetime value \n",
    "    lesotho_demand_df['hour'] = pd.to_datetime(lesotho_demand_df['hour'])          # converting hour column from string value to datetime value \n",
    "    lesotho_demand_df['hour'] = lesotho_demand_df['hour'].dt.hour                  # pulling only hour value from datetime value as a float value\n",
    "    \n",
    "    lesotho_demand_df['hour'] = lesotho_demand_df['hour']+1                        # converting hour from counting 0-23 to 1-24 \n",
    "    \n",
    "    lesotho_demand_df['system_demand_[mw]'] = lesotho_demand_df['system_demand_[mw]']/1000  # converting raw data from KW to MW by dividing by 1000\n",
    "    lesotho_demand_df = lesotho_demand_df[['hour','day','month','year','system_demand_[mw]']].astype('int')\n",
    "    \n",
    "    lesotho_demand_df.to_csv(b , index=False)                                      # exporting a csv file into given directory\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Namibia Data Cleaning Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a User-defined function UDF of the above code \n",
    "\n",
    "def NA_df_cleaning(a,b):\n",
    "    \"\"\" This function will clean raw data sets in the format of the NA_Hourly_Load_Generation_Imports_2018 xlsx file\n",
    "        and create a dataframe with the demand,hour,year,month,day columns from the dataset. Then it will export a csv file to your directory. \n",
    "        - The arugment 'a' is the path to where you stored your xlsx file with the data set to clean \n",
    "        - The argument 'b' is the path to where you want to store the new 'clean' csv file dataframe: \n",
    "                    example - '/(your desired directory path)/(name of file).csv' \"\"\"  \n",
    "    \n",
    "    path = a                                            # give location of file you want to read inbetween ''\n",
    "    namibia_df = pd.read_excel(path)                    # reads xlsx file using pandas and states first columm including index \n",
    "    \n",
    "    namibia_demand_df = namibia_df.iloc[:, 0:2].copy()  # create a data frame using the first 3 columns including index \n",
    "    \n",
    "    # change the column names in the data frame w/ inplace = True\n",
    "    namibia_demand_df.rename(columns={\"Date Time\":\"date_time\", \"System Demand [MW]\":\"system_demand_[mw]\"}, inplace = True)\n",
    "    namibia_demand_df['date_time'] = namibia_demand_df['date_time'].astype('str')                  # changing date_time data type into string \n",
    "    \n",
    "    namibia_demand_df[['date','hour']] = namibia_demand_df.date_time.str.split(\" \", expand=True)   # spliting the date_time column into 2 new columns titled date and hour   \n",
    "    namibia_demand_df[['year','month','day']] = namibia_demand_df.date.str.split(\"-\", expand=True) # splitint the date column into 3 new columns titled year month day \n",
    "    \n",
    "    NA_demand_df = namibia_demand_df.iloc[:, 1:7].copy()                # creating new dataframe not including first column at 0  \n",
    "    NA_demand_df.drop(columns= \"date\", inplace = True , axis = 1)       # droping column titled \"date\" from dataframe\n",
    "    \n",
    "    NA_demand_df['hour'] = pd.to_datetime(NA_demand_df['hour'])         # converting hour column from string into datetime values\n",
    "    NA_demand_df['hour'] = NA_demand_df['hour'].dt.hour                 # converting hour columning to only show hour value as float value\n",
    "    NA_demand_df['hour'] = NA_demand_df['hour']+1                       # changing hour from 0-23 to 1-24 \n",
    "    \n",
    "    NA_demand_df = NA_demand_df.drop(NA_demand_df.index[8760])          # Dropping last row in dataframe because not a part of timeseries\n",
    "    NA_demand_df = NA_demand_df.round(0).astype(int)                    # converting dataframe into int values by rounding values first\n",
    "    NA_demand_df.to_csv(b , index=False)                                # exporting a csv file into given directory\n",
    "    \n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Republic of South Africa Data Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a User-defined function UDF for Republic of South Africa electricity demand data set \n",
    "\n",
    "def south_africa_df_cleaning(a,b):\n",
    "    \"\"\" This function will clean raw data sets in the format of the Eskom_RSA_Load_RE_Jan_2016_Jun_2019 xlsx file\n",
    "        and create a dataframe with the demand,hour,year,month,day columns from the dataset. Then it will export a csv file to your directory. \n",
    "        - The arugment 'a' is the path to where you stored your xlsx file with the data set to clean \n",
    "        - The argument 'b' is the path to where you want to store the new 'clean' csv file dataframe: \n",
    "                    example - '/(your desired directory path)/(name of file).csv' \"\"\"  \n",
    "    \n",
    "    path = a                                                               # give location of file you want to read inbetween ''\n",
    "    SA_sheets_data = pd.read_excel(path, sheet_name = ['RE_Hourly_kWh','System_Hourly_MWh']) # loads both sheets of the xlsx raw data set as a OrderedDict \n",
    "    south_africa_df = pd.read_excel(path, sheet_name = 1)                  # putting the second sheet from the xlsx file and automatically turns the results into a dataframe  \n",
    "    SA_demand_df = south_africa_df.iloc[:, 0:3].copy()                     # create a data frame using the first 3 columns including index\n",
    "\n",
    "    # change the column names in the data frame w/ inplace = True\n",
    "    SA_demand_df.rename(columns={\"SETTLEMENT_DATE\":\"date\", \"PERIOD\":\"hour\", \"SYSTEMENERGY\": \"system_demand_[mw]\"}, inplace = True) \n",
    "    \n",
    "    SA_demand_df['date'] = SA_demand_df['date'].astype('str')              # changing date data type into string  \n",
    "    SA_demand_df[['year','month','day']] = SA_demand_df.date.str.split(\"-\", expand=True) # splitint the date column into 3 new columns titled year month day\n",
    "    SA_2018_demand_df = SA_demand_df.loc[SA_demand_df['year']== '2018']    # creating the dataframe that contains the information associated with the year of 2018\n",
    "    SA_2018_demand_df.reset_index(inplace = True)  \n",
    "    south_africa_2018_demand_df = SA_2018_demand_df.iloc[:, 2:7].copy()    # creating new dataframe not including first two columns at 0 and 1\n",
    "    \n",
    "    # changed the values of the hour column ranging from (0,23) to (1,24) using .replace() \n",
    "    south_africa_2018_demand_df['hour'] = south_africa_2018_demand_df['hour']+1\n",
    "    \n",
    "    south_africa_2018_demand_df = south_africa_2018_demand_df[['hour','day','month','year','system_demand_[mw]']].astype('int')\n",
    "    south_africa_2018_demand_df.to_csv(b , index=False)                    # exporting a csv file into given directory\n",
    "    \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tanzania Data Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a User-defined function UDF for Tanzania electricity demand data set  \n",
    "\n",
    "def TZ_df_cleaning(a,b):\n",
    "    \"\"\" This function will clean raw data sets in the format of the TZ_Hourly_Load_Generation_Data_2018 xlsx file\n",
    "        and create a dataframe with the demand,hour,year,month,day columns from the dataset. Then it will export a csv file to your directory. \n",
    "        - The arugment 'a' is the path to where you stored your xlsx file with the data set to clean \n",
    "        - The argument 'b' is the path to where you want to store the new 'clean' csv file dataframe: \n",
    "                    example - '/(your desired directory path)/(name of file).csv' \"\"\" \n",
    "  \n",
    "    path = a \n",
    "    TZ_raw_data_df = pd.read_excel(path)\n",
    "    tanzania_df = TZ_raw_data_df[['DATE','TIME','HG GRAND TOTAL']].copy()              # creating dataframe with desired columns, data, time, and HG Grand total\n",
    "    tanzania_df.rename(columns={\"DATE\":\"date\",\"TIME\":\"hour\", \"HG GRAND TOTAL\":\"system_demand_[mw]\"}, inplace = True) # change the column names in the data frame w/ inplace = True\n",
    "    \n",
    "    tanzania_df['date'] = tanzania_df['date'].ffill( axis = 0)                         # using front fill function to fill missing values for the date  \n",
    "    tanzania_df['date'] = tanzania_df['date'].astype('str')                            # changing date_time data type into string \n",
    "    tanzania_df[['year','month','day']] = tanzania_df.date.str.split(\"-\", expand=True) # spliting the date column into 3 new columns titled year month day\n",
    "\n",
    "    TZ_demand_df = tanzania_df.iloc[:, 1:8].copy()                                     # creating new dataframe not including first column at 0\n",
    "    TZ_demand_df['hour'] = TZ_demand_df['hour'].astype('str')                          # converting to string to convert to datetime value\n",
    "    TZ_demand_df['hour'] = pd.to_datetime(TZ_demand_df['hour'])                        # converting hour column from string value to datetime value \n",
    "    TZ_demand_df['hour'] = TZ_demand_df['hour'].dt.hour                                # pulling only hour value from datetime value as a float value\n",
    "    TZ_demand_df['hour'] = TZ_demand_df['hour'].replace(0, 24)                         # Replacing the 0 values with 24 , the time count was 1...23,0\n",
    "    TZ_demand_df = TZ_demand_df[['hour','day','month','year','system_demand_[mw]']].astype('int')\n",
    "    TZ_demand_df.to_csv(b , index=False)                                               # exporting a csv file into given directory\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Zimbabwe Data Cleaning Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a User-defined function UDF of the above code \n",
    "\n",
    "def zimbabwe_df_cleaning(a,b,c):\n",
    "    \"\"\" This function will clean raw data sets in the format of the ZESA_Hourly_Load_2018_Data xlsx file\n",
    "        and create a dataframe with the demand,hour,year,month,day columns from the dataset. Then it will export a csv file to your directory. \n",
    "        - The arugment 'a' is the path to where you stored your xlsx file with the data set to clean \n",
    "        - The argument 'b' is the path to where you want to store the new 'clean' csv file dataframe: \n",
    "                    example - '/(your desired directory path)/(name of file).csv' \n",
    "        - the argument 'c' is the year you want to pull information for in the original spreadsheet in the form of an integer\"\"\" \n",
    "\n",
    "    zimbabwe_demand_df = pd.DataFrame(columns=['hour', 'day', 'month', 'year', 'system_demand_[mw]'])  # Creating an empty Dataframe with column names only\n",
    "    selected_year = c                                                                                  # year of the selected spreadsheet \n",
    "    year = str(c)                                                                                      # creating year value as a string for loop \n",
    "    path = a                                                                                           # give location of file you want to read inbetween ''\n",
    "    \n",
    "    # vector with name of sheet in raw dataset \n",
    "    month_year = (\"January \"+ year,\"February \"+ year,\"March \"+ year,\n",
    "                  \"April \"+ year,\"May \"+year,\"June \"+year,\"July \"+year,\n",
    "                  \"Aug \"+year,\"Sept \"+year,\"Oct \"+year,\"Nov \"+year, \"Dec \"+year)\n",
    "\n",
    "    # creating loop that loops through two variables simulanteously \n",
    "    for i, m in zip(range(13), range(1,13)):\n",
    " \n",
    "        z_raw_data_df = pd.read_excel(path, sheet_name = month_year[i])               # pulling the second sheet from the xlsx file and automatically turns the results into a dataframe \n",
    "        # creating dataframe with desired columns, data, time, and HG Grand total\n",
    "        zim_df = z_raw_data_df.loc[:, 'Unnamed: 1':'Monthly Peak Demand (MW)'].copy() # picking desired columns by column name\n",
    "        zim_df = zim_df.loc[:, zim_df.columns != 'Monthly Peak Demand (MW)']          # dropping column titled 'Monthly Peak Demand (MW)'\n",
    " \n",
    "        zim_df.drop(index=[0,25,26], inplace = True , axis = 0)                       # droping rows from dataframe\n",
    "        zim_demand_df = pd.melt(zim_df, id_vars=['Unnamed: 1'] , var_name='day', value_name='system_demand_[mw]') # using melt function to stack multiple columns into manageable columns\n",
    "    \n",
    "        zim_demand_df.insert(2,\"month\",m)                                     # creating column titled \"month\" with value m and inserting into the 2 column position\n",
    "        zim_demand_df.insert(3,\"year\",c)                                      # creating column titled \"year\" with value 2018 and inserting into the 3 column position\n",
    "\n",
    "        zim_demand_df.rename(columns = {\"Unnamed: 1\":\"hour\"}, inplace = True) # renaming unnamed column with hour \n",
    "        zim_demand_df['hour'] = zim_demand_df['hour'].astype('str')           # converting to string to convert to datetime value\n",
    "        zim_demand_df['hour'] = pd.to_datetime(zim_demand_df['hour'])         # converting hour column from string value to datetime value \n",
    "        zim_demand_df['hour'] = zim_demand_df['hour'].dt.hour                 # pulling only hour value from datetime value as a float value\n",
    "        zim_demand_df['hour'] = zim_demand_df['hour'].replace(0, 24)          # replacing hour values with 0 to 24 \n",
    "        zimbabwe_demand_df = zimbabwe_demand_df.append(zim_demand_df,ignore_index=True) # appending data frame create for each month to the end of the orginal janurary dataframe \n",
    "\n",
    "    zimbabwe_demand_df = zimbabwe_demand_df[['hour','day','month','year','system_demand_[mw]']].astype('int')\n",
    "    zimbabwe_demand_df.to_csv(b , index=False)                                      # exporting a csv file into given directory\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mozambique Data Cleaning Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a User-defined function UDF of the above code \n",
    "\n",
    "def mozambique_df_cleaning(a,b,c):\n",
    "    \"\"\" This function will clean raw data sets in the format of the EDM Hourly_Load_2017_2018_Data xlsx file\n",
    "        and create a dataframe with the demand,hour,year,month,day columns from the dataset. Then it will export a csv file to your directory. \n",
    "        - The arugment 'a' is the path to where you stored your xlsx file with the data set to clean \n",
    "        - The argument 'b' is the path to where you want to store the new 'clean' csv file dataframe: \n",
    "                    example - '/(your desired directory path)/(name of file).csv' \n",
    "        - The argument 'c' is the year (in the form of an integer) on the spreadsheet you want to pull information for\"\"\" \n",
    "\n",
    " \n",
    "    # this loop will append to an empty data frame created below \n",
    "    Mozambique_demand_df = pd.DataFrame(columns=['hour','system_demand_[mw]','year','day','month'])  # Creating an empty Dataframe with column names only\n",
    "\n",
    "    month_start_row = (0,28,56,84,112,140,168,196,224,252,280,308)                                   # the index of the row for when each month starts \n",
    "    month_end_column = (33,30,33,32,33,32,33,33,32,33,32,33)                                         # the last column number where each month ends\n",
    "    year = str(c)\n",
    "    path = a                                                                                         # give location of file you want to read inbetween ''\n",
    "\n",
    "    # creating loop to clean the data set a few selected rows at a time \n",
    "    for i, j in zip(range(0,12), range(0,12)):\n",
    "    \n",
    "        Mozambique_raw_data_df = pd.read_excel(path, sheet_name = year)                              # pulling the second sheet from the xlsx file and automatically turns the results into a dataframe\n",
    "         \n",
    "        Moz_df = Mozambique_raw_data_df.iloc[month_start_row[i]:month_start_row[i]+25,:].copy()      # pulling rows 0-25 into a dataframe\n",
    "        Moz_df = Moz_df.iloc[:, 1:month_end_column[j]]                                               # selecting columns for 1-##\n",
    "        Moz_df.columns = Moz_df.iloc[0]                                                              # renaming columns with the first row \n",
    "        Moz_df = Moz_df.drop(Moz_df.index[0])                                                        # dropping first row \n",
    "    \n",
    "        # 2018 spreadsheet is missing values, so this if statement applies to 2018 spreadsheet  \n",
    "        if c == 2018:\n",
    "            Moz_df = Moz_df.ffill(axis = 1)                                                          # filling missing NaN values with values in the column infront of it \n",
    "\n",
    "        Moz_demand_df = pd.melt(Moz_df, id_vars=['Hour Ending'] , var_name='date', value_name='system_demand_[mw]')  # using melt function to stack multiple columns into manageable columns\n",
    "        Moz_demand_df['date'] = Moz_demand_df['date'].astype('str')                                  # changing date_time data type into string\n",
    "\n",
    "        # spliting the date column into 3 new columns titled year month day \n",
    "        Moz_demand_df[['year','month','day']] = Moz_demand_df.date.str.split(\"-\", expand=True)\n",
    "        Moz_demand_df.drop([\"date\"], axis=1, inplace = True)                                         # droping columns titled data and time\n",
    "    \n",
    "        Moz_demand_df['year'] = Moz_demand_df['year'].replace('2004', value = year)\n",
    "        Moz_demand_df = Moz_demand_df.rename(columns = {'Hour Ending': 'hour'})\n",
    "    \n",
    "        Mozambique_demand_df = Mozambique_demand_df.append(Moz_demand_df,ignore_index=True)          # appending data frame create for each month to the end of the orginal janurary dataframe \n",
    "\n",
    "    Mozambique_demand_df = Mozambique_demand_df[[\"hour\",\"day\",\"month\",\"year\",\"system_demand_[mw]\"]].astype('int')  # rearranging columns in data frame \n",
    "    Mozambique_demand_df.to_csv(b , index=False)                                                     # exporting a csv file into given directory\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Eswatini Data Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a User-defined function UDF of the above code \n",
    "\n",
    "def eswatini_df_cleaning(a,b,c):\n",
    "    \"\"\" This function will clean raw data sets in the format of the EDM Hourly_Load_2017_2018_Data xlsx file\n",
    "        and create a dataframe with the demand,hour,year,month,day columns from the dataset. Then it will export a csv file to your directory. \n",
    "        - The arugment 'a' is the path to where you stored your xlsx file with the data set to clean \n",
    "        - The argument 'b' is the path to where you want to store the new 'clean' csv file dataframe: \n",
    "                    example - '/(your desired directory path)/(name of file).csv' \n",
    "        - The argument 'c' is the year (in the form of an integer) on the spreadsheet you want to pull information for\n",
    "        - I made corrections on orginal xlsx file for the dates because date 1/13/18-1/20/18 were in a different format than the others, double check dates are in the same format\"\"\" \n",
    "\n",
    "    path = a                                                          # imported xlsx file\n",
    "    year = str(c)                                                     # converting c value to string value \n",
    "    Eswatini_raw_data_df = pd.read_excel(path, sheet_name = year)     # pulling the second sheet from the xlsx file and automatically turns the results into a dataframe \n",
    "    Eswatini_df = Eswatini_raw_data_df[['DATE','TIME','SYST']]        # selecting columns 'DATE', 'TIME','SYST' and creating data frame\n",
    "    \n",
    "    # changing date_time data type into string \n",
    "    Eswatini_df['DATE'] = Eswatini_df['DATE'].astype('str') \n",
    "    # spliting the date_time column into 2 new columns titled date and hour \n",
    "    Eswatini_df[['date','unused_hours']] = Eswatini_df.DATE.str.split(\" \", expand=True)\n",
    "    # splitint the date column into 3 new columns titled year month day \n",
    "    Eswatini_df[['year','month','day']] = Eswatini_df.date.str.split(\"-\", expand=True)\n",
    "    \n",
    "    hours = pd.Series(range(1,25)) # creating vector with values 1 -24 \n",
    "    hours_set = hours.repeat(2).reset_index(drop = True)              # repeating values in hours vector each twice (to much hour and half-hour value)\n",
    "    total_hours = pd.concat([hours_set]*365, ignore_index=True)       # have the vector repeat 365 times to correspond to the number of hours in a year \n",
    "    Eswatini_df.loc[:,'hour'] = total_hours                           # creating new column titled 'hour' with values of the vector = total hours\n",
    "    \n",
    "    count = pd.Series(range(8760))                                    # creating vector count with total hours in a year \n",
    "    double_count = count.repeat(2).reset_index(drop = True)           # repeating each value in vector count twice to match half-hour and hour values \n",
    "    Eswatini_df['count'] = double_count                               # creating new column 'count' with values = doube_count vector \n",
    "    \n",
    "    # converting day, month and year columns into numeric values to use mean() for groupby ()\n",
    "    Eswatini_df['day'] = pd.to_numeric(Eswatini_df.day)\n",
    "    Eswatini_df['month'] = pd.to_numeric(Eswatini_df.month)\n",
    "    Eswatini_df['year'] = c\n",
    "\n",
    "    group_Eswatini = Eswatini_df.groupby('count').mean()              # using group,by function to group by count, taking 17520 values to 8760 values \n",
    "    \n",
    "    Eswatini_demand_df = group_Eswatini[['hour','day','month','year','SYST']].reset_index(drop = True)    # creating data frame with selected columns with index reset, dropping 'count' index \n",
    "    Eswatini_demand_df = Eswatini_demand_df.rename(columns = {\"SYST\": \"system_demand_[mw]\"})              # changing column name 'syst' to name 'system_demand_[mw]' \n",
    "    \n",
    "    Eswatini_demand_df = Eswatini_demand_df[['hour','day','month','year','system_demand_[mw]']]\n",
    "    Eswatini_demand_df.to_csv(b , index=False)                                                            # exporting a csv file into given directory\n",
    "    \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Zambia Data Cleaning Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a User-defined function UDF of the above code \n",
    "\n",
    "def zambia_df_cleaning(a,b):\n",
    "    \"\"\" This function will clean raw data sets in the format of the SACREE RE Project Data Collection ZESCO xlsx file\n",
    "        and create a dataframe with the demand,hour,year,month,day columns from the dataset. Then it will export a csv file to your directory. \n",
    "        - The arugment 'a' is the path to where you stored your xlsx file with the data set to clean \n",
    "        - The argument 'b' is the path to where you want to store the new 'clean' csv file dataframe: \n",
    "                    example - '/(your desired directory path)/(name of file).csv' \n",
    "        - This function does not include data from the year 2017 or 2019 which are located on the spreadsheet\"\"\"  \n",
    "    \n",
    "    path = a\n",
    "    zambia_raw_data_df = pd.read_excel(path, sheet_name = \"Demand Data\")     # pulling the second sheet from the xlsx file and automatically turns the results into a dataframe \n",
    "    \n",
    "    zambia_df = zambia_raw_data_df.drop(zambia_raw_data_df.index[0:26])                   # dropping 0-26 from raw data set \n",
    "    zambia_demand_df = zambia_df[['Unnamed: 1','Unnamed: 5']]                             # creating dataframe with selected columns\n",
    "    zambia_demand_df = zambia_demand_df.drop(zambia_demand_df.index[0:3])                 # dropping first 3 rows \n",
    "    zambia_demand_df.rename(columns={\"Unnamed: 1\":\"hour_per_year\", \"Unnamed: 5\":\"system_demand_[mw]\"}, inplace = True) # renaming columns\n",
    "    zambia_demand_df = zambia_demand_df.reset_index(drop=True)                            # reseting index and droping old index \n",
    "    \n",
    "    zam_list = []                            # empty list to store dates generated by loop\n",
    "    # Creating values for loop to build date column with dates ranging from 1-1-2018 to 12-31-2018 \n",
    "    start_date = date(2018, 1, 1)            # start date for column\n",
    "    end_date = date(2018, 12, 31)            # end date for column \n",
    "    delta = end_date - start_date            # as timedelta for loop\n",
    "\n",
    "    # loop to print date starting from 1-1-2018 and store into zam_list \n",
    "    for i in range(delta.days + 1):\n",
    "        day = start_date + timedelta(days=i) # building date with i iterations\n",
    "        zam_list.append(day)                 # adding to empty list \n",
    "    \n",
    "    zambia_series = pd.Series(zam_list)      # building series to repeat dates to match hours in a year\n",
    "    zambia_repeat = zambia_series.repeat(24).reset_index(drop = True)   # repeat each date 24 times to much hours, totla 8760 hours\n",
    "    zambia_date_df = pd.DataFrame({'date': zambia_repeat})              # creating zam list into \"date\" dataframe  \n",
    "    zambia_demand_df.insert(1,\"date\",zambia_date_df)                    # adding date column to zambia demand df \n",
    "    \n",
    "    # creating values for the hour column in the data frame \n",
    "    hours_day = pd.Series(range(1,25))       # making a vector of the values 1-24 \n",
    "    hours = pd.concat([hours_day]*365, ignore_index=True)               # have the vector repeat 365 times to correspond to the number of hours in a year \n",
    "    zambia_demand_df['hour'] = hours         # creating column named hours with the repeating value 1-24 'hours' for each day in each month of the year \n",
    "\n",
    "    zambia_demand_df = zambia_demand_df.drop(zambia_demand_df.index[8760])                          # drop last row in dataframe because it wasn't needed \n",
    "    zambia_demand_df['date'] = zambia_demand_df['date'].astype('str')                               # changing date data type into string \n",
    "    zambia_demand_df[['year','month','day']] = zambia_demand_df.date.str.split(\"-\", expand=True)    # spliting the date column into 3 new columns titled year month day \n",
    "    zambia_demand_df = zambia_demand_df[['hour','day','month', 'year', 'system_demand_[mw]']].astype('int')       # rearranging columns and created updated dataframe \n",
    "    \n",
    "    zambia_demand_df.to_csv(b , index=False)                            # exporting a csv file into given directory\n",
    "    \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Malawi Data Cleaning Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a User-defined function UDF of the above code \n",
    "\n",
    "def malawi_df_cleaning(a,b):\n",
    "    \"\"\" This function will clean raw data sets in the format of the HOURLY TOTALS GENERATED APRIL 2018.xlsx file found in the malawi_data folder\n",
    "        and create a dataframe with the demand,hour,year,month,day columns from the dataset. Then it will export a csv file to your directory. \n",
    "        - The arugment 'a' is the path to which folder you stored your xlsx file with the data set to clean \n",
    "        - The argument 'b' is the path to where you want to store the new 'clean' csv file dataframe: \n",
    "                    example - '/(your desired directory path)/(name of file).csv' \n",
    "        - Make sure the files in each folder in the malawi data called (data_20xx) are sorted by name. \n",
    "            (The first file should be the one for april, last file should be the one fore september) \n",
    "        - I made corrections on orginal xlsx files by making adjustments to file name, sheet name so that all files can be in the same format\n",
    "        - I also made corrects to missing values in the original data sets by taking\n",
    "            the average between days (for missing values for a day) and hours (for missing values for certain hours)\n",
    "        - This function cleans each data_20xx folder in the malawi data folder seperately\"\"\"\n",
    "    \n",
    "    malawi_demand_df = pd.DataFrame(columns=['hour', 'day', 'month', 'year', 'system_demand_[mw]'])  # Creating an empty Dataframe with column names only\n",
    "    \n",
    "    # Creating loop that list all files in the selected directory\n",
    "    # files are then read in and then can run code to clean each file \n",
    "    \n",
    "    entries = os.listdir(a)\n",
    "    month_days = (30,31,31,28,31,31,30,31,31,30,31,30)\n",
    "    \n",
    "    for i, entry in zip(range(12), entries):\n",
    "        path_pt1 = a+'/'\n",
    "        path_pt2 = entry\n",
    "        path = str(entry)\n",
    "        malawi_month_df = pd.read_excel(path_pt1+path)     # pulling the second sheet from the xlsx file and automatically turns the results into a dataframe \n",
    "        \n",
    "        malawi_raw_data = malawi_month_df.iloc[4:53,].copy() #creating data frames with the rows from row 4 to row 52 \n",
    "    \n",
    "        # deleting header and moving all rows up \n",
    "        new_header = malawi_raw_data.iloc[0] #grab the first row for the header\n",
    "        malawi_raw_data = malawi_raw_data[1:] #take the data less the header row\n",
    "        malawi_raw_data.columns = new_header #set the header row as the df header\n",
    "        \n",
    "        month_data_df = malawi_raw_data.reset_index(drop =True) # reseting index and with new name data frame \n",
    "        \n",
    "        # need to do this for all columns\n",
    "        month_demand_df = pd.melt(month_data_df, id_vars=['TIME'] , var_name='date', value_name='system_demand_[mw]')\n",
    "        \n",
    "        # changing date_time data type into string \n",
    "        month_demand_df['date'] = month_demand_df['date'].astype('str') \n",
    "        \n",
    "        # spliting the date column into 3 new columns titled year month day \n",
    "        month_demand_df[['year','month','day']] = month_demand_df.date.str.split(\"-\", expand=True)\n",
    "\n",
    "        # This needs to be adjusted to each month because they have different total number of days\n",
    "        hours = pd.Series(range(1,25))\n",
    "        hours_set = hours.repeat(2).reset_index(drop = True)\n",
    "        total_hours = pd.concat([hours_set]*month_days[i], ignore_index=True) # have the vector repeat 31 times to correspond to the number of hours in a month \n",
    "\n",
    "        month_demand_df.loc[:,'hour'] = total_hours # creating hour column with double hour count \n",
    "        \n",
    "        # Creating a count to use for group.by funciton\n",
    "        # range is total number of hours in a month, this will be different for each month \n",
    "        count = pd.Series(range(24*month_days[i])) # different for each month \n",
    "        double_count = count.repeat(2).reset_index(drop = True)\n",
    "        \n",
    "        month_demand_df['count'] = double_count # creating count column to use for group.by function \n",
    "        \n",
    "        # converting day, month and year columns into numeric values to use mean() for groupby ()\n",
    "        month_demand_df['day'] = pd.to_numeric(month_demand_df.day)\n",
    "        month_demand_df['month'] = pd.to_numeric(month_demand_df.month)\n",
    "        month_demand_df['year'] = pd.to_numeric(month_demand_df.year)\n",
    "        month_demand_df['system_demand_[mw]'] = month_demand_df['system_demand_[mw]'].astype('int')\n",
    "        \n",
    "        b_groupby = month_demand_df.groupby('count').mean() # using groupby function to average half hour time demand to hour time demand\n",
    "\n",
    "        month_demand_df = b_groupby[['hour','day','month','year','system_demand_[mw]']].reset_index(drop = True) # rearranging columns to match desired format\n",
    "\n",
    "        month_demand_df = month_demand_df.astype('int') # making all columns in the data frame into int values to be consistant \n",
    "        \n",
    "        malawi_demand_df = malawi_demand_df.append(month_demand_df,ignore_index=True) # appending data frame create for each month to the end of the orginal janurary dataframe \n",
    "        \n",
    "        malawi_demand_df = malawi_demand_df.sort_values(by=['year','month', 'day','hour'])\n",
    "        \n",
    "    malawi_demand_df.to_csv(b, index=False)                                      # exporting a csv file into given directory\n",
    "     \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesotho_df_cleaning('/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/Data/Lesotho_Load_Profile_2017_2019.xlsx',\n",
    "                    '/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/demand_dataframe/lesotho_df_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NA_df_cleaning('/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/Data/NA_Hourly_Load_Generation_Imports_2018.xlsx',\n",
    "               '/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/demand_dataframe/namibia_df_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "south_africa_df_cleaning('/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/Data/Eskom_RSA_Load_RE_Jan_2016_Jun_2019.xlsx',\n",
    "                         '/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/demand_dataframe/south_africa_df_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TZ_df_cleaning('/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/Data/TZ_Hourly_Load_Generation_Data_2018.xlsx',\n",
    "               '/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/demand_dataframe/tanzania_df_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "zimbabwe_df_cleaning('/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/Data/ZESA_Hourly_Load_2018_Data.xlsx',\n",
    "                     '/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/demand_dataframe/zimbabwe_df_2018.csv',2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "mozambique_df_cleaning('/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/Data/EDM Hourly_Load_2017_2018_Data.xlsx',\n",
    "                       '/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/demand_dataframe/mozambique_df_2018.csv',2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "eswatini_df_cleaning('/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/Data/ESWATINI SYSTEM HALF HOURLY LOAD DATA-2017 2018.xlsx',\n",
    "                     '/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/demand_dataframe/eswatini_df_2018.csv',2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "zambia_df_cleaning('/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/Data/SACREE RE Project Data Collection ZESCO.xlsx',\n",
    "                   '/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/demand_dataframe/zambia_df_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "malawi_df_cleaning('/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/Malawi/malawi_data/malawi_data_2018',\n",
    "                   '/Users/Tiana/Desktop/ENVS_199RA_winter20/Southern_Africa_Electricity/demand_dataframe/malawi_df_2018.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Angola Data Cleaning Funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a User-defined function UDF of the above code \n",
    "\n",
    "def Angola_df_cleaning(a,b):\n",
    "    \"\"\" This function will clean raw data sets in the format of the Lesotho_Load_Profile_2017_2019 xlsx file\n",
    "        and create a dataframe with the demand,hour,year,month,day columns from the dataset. Then it will export a csv file to your directory. \n",
    "        - The arugment 'a' is the path to where you stored your xlsx file with the data set to clean \n",
    "        - The argument 'b' is the path to where you want to store the new 'clean' csv file dataframe: \n",
    "                    example - '/(your desired directory path)/(name of file).csv' \"\"\" \n",
    "    \n",
    "    path = a\n",
    "    Angola_raw_data = pd.read_csv(path) # importing csv file with Angola raw dataset \n",
    "    Angola_demand = Angola_raw_data.iloc[3:369,1:27] # creating dataframe selecting desired rows and columns\n",
    "    Angola_demand = Angola_demand.reset_index(drop = True) # reseting index\n",
    "\n",
    "    new_header = Angola_demand.iloc[0] # making first row into header for dataframe\n",
    "    Angola_demand = Angola_demand[1:] # making dataframe into every row after first row\n",
    "    Angola_demand.columns = new_header # inserting new header into dataframe\n",
    "    \n",
    "    Angola_demand = Angola_demand.drop(columns = 'Dia') # dropping column called 'Dia'\n",
    "    Angola_demand = Angola_demand.set_index('Data') # making data column into index column to apply stack funciton\n",
    "    new_Angola_demand_df = Angola_demand.stack() #using stack function to sack desired columns into one column with corresponding hour\n",
    "    Angola_demand_2018 = new_Angola_demand_df.to_frame() # changing data set type into a dataframe\n",
    "\n",
    "    Angola_demand_2018 = Angola_demand_2018.rename(columns={0:\"system_demand_[MW]\"}) # renaming columns in dataframe\n",
    "    Angola_demand_2018 = Angola_demand_2018.reset_index() # reseting index to make date column into first column of dataset\n",
    "    Angola_demand_2018 = Angola_demand_2018.rename(columns = {\"Data\":\"date\",0:\"hour\"}) # renaming columns in dataframe\n",
    "    Angola_demand_2018[\"date\"].astype(str) # changinging 'date' column into string to split date into 3 columns\n",
    "    \n",
    "    # spliting date column into 3 columns divided by / to have a month, day and year column\n",
    "    Angola_demand_2018[['month','day','year']] = Angola_demand_2018.date.str.split(\"/\",expand=True,)\n",
    "    Angola_demand_2018['hour'] = Angola_demand_2018['hour'].astype(int) # changing sting data type into int data type\n",
    "    Angola_demand_2018['hour'] = Angola_demand_2018['hour']+1 # changing hour column from 0-23 to 1-24\n",
    "    \n",
    "    Angola_demand_2018['year'] = Angola_demand_2018['year'].astype(int) # changing year column into int data type\n",
    "    Angola_demand_2018['year'] = Angola_demand_2018['year']+2000 # chaning year column value from 18 to 2018\n",
    "    \n",
    "    Angola_demand_2018['system_demand_[MW]'] = Angola_demand_2018['system_demand_[MW]'].astype(str) # change column to string value to take out comma\n",
    "    Angola_demand_2018['system_demand_[MW]'] = Angola_demand_2018['system_demand_[MW]'].str.replace(',', '') # removing comma from data values\n",
    "    # rearranging columns in dataframe \n",
    "    Angola_demand_2018 = Angola_demand_2018[['hour','day','month','year','system_demand_[MW]']] # rearranging columns in dataset \n",
    "    Angola_demand_2018[['hour','day','month']] = Angola_demand_2018[['hour','day','month']].astype(int) # changing columns into int values\n",
    "    Angola_demand_2018['system_demand_[MW]'] = Angola_demand_2018['system_demand_[MW]'].astype(float) # converting column to float value because it has values after the decimal                                                                \n",
    "\n",
    "    Angola_demand_2018.to_csv(b , index=False)                                      # exporting a csv file into given directory\n",
    "    \n",
    "    return \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
